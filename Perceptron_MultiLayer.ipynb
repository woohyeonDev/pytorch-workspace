{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
    "          nn.Sigmoid(),\n",
    "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
    "          nn.Sigmoid()\n",
    "          ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6932249069213867\n",
      "100 0.6931095719337463\n",
      "200 0.6930636167526245\n",
      "300 0.6930121183395386\n",
      "400 0.6929492950439453\n",
      "500 0.6928672790527344\n",
      "600 0.6927525997161865\n",
      "700 0.6925811767578125\n",
      "800 0.6923026442527771\n",
      "900 0.6917972564697266\n",
      "1000 0.6907176375389099\n",
      "1100 0.6877463459968567\n",
      "1200 0.6758202910423279\n",
      "1300 0.6183861494064331\n",
      "1400 0.4520728886127472\n",
      "1500 0.05744911730289459\n",
      "1600 0.016801845282316208\n",
      "1700 0.008648993447422981\n",
      "1800 0.005551439709961414\n",
      "1900 0.003992401994764805\n",
      "2000 0.00307508185505867\n",
      "2100 0.00247910525649786\n",
      "2200 0.0020645218901336193\n",
      "2300 0.001761286985129118\n",
      "2400 0.001530878827907145\n",
      "2500 0.001350490958429873\n",
      "2600 0.001205791370011866\n",
      "2700 0.0010874515864998102\n",
      "2800 0.0009889061329886317\n",
      "2900 0.0009058378636837006\n",
      "3000 0.0008348425617441535\n",
      "3100 0.0007735849358141422\n",
      "3200 0.0007202279521152377\n",
      "3300 0.0006733406335115433\n",
      "3400 0.0006318773375824094\n",
      "3500 0.000594926648773253\n",
      "3600 0.0005618590512312949\n",
      "3700 0.0005320353084243834\n",
      "3800 0.0005051032640039921\n",
      "3900 0.0004805637872777879\n",
      "4000 0.00045823759865015745\n",
      "4100 0.0004377495788503438\n",
      "4200 0.0004189229221083224\n",
      "4300 0.00040156839531846344\n",
      "4400 0.00038554437924176455\n",
      "4500 0.00037065488868393004\n",
      "4600 0.00035682268207892776\n",
      "4700 0.0003439328575041145\n",
      "4800 0.00033187930239364505\n",
      "4900 0.0003206371038686484\n",
      "5000 0.0003100771573372185\n",
      "5100 0.00030013956711627543\n",
      "5200 0.00029082069522701204\n",
      "5300 0.0002820208901539445\n",
      "5400 0.0002736893657129258\n",
      "5500 0.0002658342127688229\n",
      "5600 0.00025837795692496\n",
      "5700 0.0002513330546207726\n",
      "5800 0.000244625611230731\n",
      "5900 0.0002382426173426211\n",
      "6000 0.00023216946283355355\n",
      "6100 0.00022639779490418732\n",
      "6200 0.0002208862133556977\n",
      "6300 0.00021562556503340602\n",
      "6400 0.00021060711878817528\n",
      "6500 0.00020579301053658128\n",
      "6600 0.0002011762117035687\n",
      "6700 0.0001967809075722471\n",
      "6800 0.00019254029029980302\n",
      "6900 0.00018847882165573537\n",
      "7000 0.00018457762780599296\n",
      "7100 0.00018084750627167523\n",
      "7200 0.00017723775818012655\n",
      "7300 0.00017375680909026414\n",
      "7400 0.0001704030582914129\n",
      "7500 0.00016717202379368246\n",
      "7600 0.00016409043746534735\n",
      "7700 0.00016106606926769018\n",
      "7800 0.00015815575898159295\n",
      "7900 0.0001553575275465846\n",
      "8000 0.00015263700333889574\n",
      "8100 0.00014999466657172889\n",
      "8200 0.00014748555258847773\n",
      "8300 0.00014504817954730242\n",
      "8400 0.00014265361824072897\n",
      "8500 0.0001403259375365451\n",
      "8600 0.00013809537631459534\n",
      "8700 0.00013593104085884988\n",
      "8800 0.00013382913311943412\n",
      "8900 0.00013178936205804348\n",
      "9000 0.00012981252803001553\n",
      "9100 0.00012786447769030929\n",
      "9200 0.00012600379704963416\n",
      "9300 0.00012417099787853658\n",
      "9400 0.00012239543139003217\n",
      "9500 0.00012064437032677233\n",
      "9600 0.00011900604295078665\n",
      "9700 0.00011736195301637053\n",
      "9800 0.00011577087570913136\n",
      "9900 0.00011420097143854946\n",
      "10000 0.00011271066614426672\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    # forward 연산\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = cross_entropy(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100의 배수에 해당되는 에포크마다 비용을 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[1.1169876e-04]\n",
      " [9.9982882e-01]\n",
      " [9.9984229e-01]\n",
      " [1.8530559e-04]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch0617",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
